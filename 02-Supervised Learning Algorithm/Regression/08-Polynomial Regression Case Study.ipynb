{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Polynomial Regression\n",
    "\n",
    "**Why Polynomial Regression?**\n",
    "\n",
    "Polynomial regression is used when the relationship between the independent variable \\( X \\) and the dependent variable \\( y \\) is not linear. In real-world scenarios, data often exhibits non-linear patterns, which cannot be captured effectively by simple linear regression. Polynomial regression can model a wide range of curves and is thus more flexible in fitting data that doesn't follow a straight line.\n",
    "\n",
    "**Use Case Example:**\n",
    "Let's consider commuting times as a function of distance. While a linear relationship might work for short distances, longer distances might show diminishing or increasing returns due to factors like traffic congestion, varying speeds, or different modes of transportation used over longer distances.\n",
    "\n",
    "**Pros and Cons of Polynomial Regression:**\n",
    "\n",
    "**Pros:**\n",
    "- **Flexibility:** Can model non-linear relationships.\n",
    "- **Better Fit:** Can provide a better fit for data that doesn't follow a straight line.\n",
    "\n",
    "**Cons:**\n",
    "- **Overfitting:** Higher-degree polynomials can lead to overfitting, capturing noise rather than the underlying trend.\n",
    "- **Complexity:** Increases with the degree of the polynomial, making interpretation and computation more difficult.\n",
    "- **Extrapolation:** Polynomial models can behave erratically outside the range of the training data.\n",
    "\n",
    "### Steps to Implement Polynomial Regression\n",
    "\n",
    "1. **Generate Sample Data**\n",
    "2. **Data Preprocessing**\n",
    "3. **Split Data into Training and Testing Sets**\n",
    "4. **Transform Features for Polynomial Regression**\n",
    "5. **Fit the Polynomial Regression Model**\n",
    "6. **Make Predictions**\n",
    "7. **Evaluate the Model**\n",
    "\n",
    "### Step 1: Generate Sample Data\n",
    "\n",
    "Let's generate sample data where commuting time exhibits a non-linear relationship with distance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code follows the steps for polynomial regression, including data generation, preprocessing, feature transformation, model fitting, prediction, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Distance      Hours\n",
      "0   8.116262  10.732550\n",
      "1  19.063572  45.574756\n",
      "2  14.907885  29.770206\n",
      "3  12.374511  19.512539\n",
      "4   3.964354   3.334116\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "distance = np.random.uniform(1, 20, 100)\n",
    "hours = 0.1 * distance**2 + 0.5 * distance + np.random.normal(0, 1, 100)\n",
    "\n",
    "data = {\n",
    "    'Distance': distance,\n",
    "    'Hours': hours\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing\n",
    "\n",
    "Ensure the data is clean and ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance    0\n",
      "Hours       0\n",
      "dtype: int64\n",
      "         Distance       Hours\n",
      "count  100.000000  100.000000\n",
      "mean     9.933434   17.995848\n",
      "std      5.652299   14.582097\n",
      "min      1.104920    0.355942\n",
      "25%      4.670814    4.976722\n",
      "50%      9.818707   14.309141\n",
      "75%     14.873859   30.430579\n",
      "max     19.750852   49.666863\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Distance']]\n",
    "y = df['Hours']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Transform Features for Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fit the Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train_poly)\n",
    "y_test_pred = model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE: 0.7034466665093435\n",
      "Training MSE: 0.8147153703416304\n",
      "Training R-squared: 0.9960376124547679\n",
      "Testing MAE: 0.577998177949695\n",
      "Testing MSE: 0.6358406072820825\n",
      "Testing R-squared: 0.997222493423401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Training set evaluation\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Testing set evaluation\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training MAE: {train_mae}')\n",
    "print(f'Training MSE: {train_mse}')\n",
    "print(f'Training R-squared: {train_r2}')\n",
    "print(f'Testing MAE: {test_mae}')\n",
    "print(f'Testing MSE: {test_mse}')\n",
    "print(f'Testing R-squared: {test_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "- **Training MAE:** Indicates the average absolute error on the training set.\n",
    "- **Training MSE:** Measures the average squared error on the training set.\n",
    "- **Training R-squared:** Shows the proportion of variance explained by the model on the training set.\n",
    "\n",
    "- **Testing MAE:** Indicates the average absolute error on the testing set.\n",
    "- **Testing MSE:** Measures the average squared error on the testing set.\n",
    "- **Testing R-squared:** Shows the proportion of variance explained by the model on the testing set.\n",
    "\n",
    "These metrics help evaluate the model's performance and generalization ability. If the training error is much lower than the testing error, the model might be overfitting. If both errors are high, the model might be underfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
