{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis in Social Media\n",
    "This solution provides a basic framework for sentiment analysis on social media posts using different machine learning algorithms and an interactive UI for real-time classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Data Preprocessing\n",
    "\n",
    "First, make sure you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (8.1.0)\n",
      "Collecting imblearn\n",
      "  Obtaining dependency information for imblearn from https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.11.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (3.0.8)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/5a/fa/267de06c95210580f4b82b45cec1ce1e9ce1f21a01a684367db89e7da70d/imbalanced_learn-0.12.3-py3-none-any.whl.metadata\n",
      "  Using cached imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (45.1.0.post20200119)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from ipywidgets import widgets, HBox, VBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic text data\n",
    "def generate_synthetic_text_data(n_samples=1000):\n",
    "    sentiments = ['positive', 'neutral', 'negative']\n",
    "    text_data = []\n",
    "    sentiment_labels = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        sentiment = np.random.choice(sentiments)\n",
    "        if sentiment == 'positive':\n",
    "            text = \" \".join([\"love\", \"great\", \"fantastic\", \"excellent\", \"good\"] * np.random.randint(1, 5))\n",
    "        elif sentiment == 'neutral':\n",
    "            text = \" \".join([\"okay\", \"fine\", \"average\", \"mediocre\", \"decent\"] * np.random.randint(1, 5))\n",
    "        else:\n",
    "            text = \" \".join([\"bad\", \"terrible\", \"awful\", \"horrible\", \"poor\"] * np.random.randint(1, 5))\n",
    "        \n",
    "        text_data.append(text)\n",
    "        sentiment_labels.append(sentiment)\n",
    "    \n",
    "    return text_data, sentiment_labels\n",
    "\n",
    "# Generate synthetic data\n",
    "texts, sentiments = generate_synthetic_text_data()\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "df = pd.DataFrame({'text': texts, 'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love great fantastic excellent good love great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love great fantastic excellent good love great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad terrible awful horrible poor bad terrible ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad terrible awful horrible poor bad terrible ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>okay fine average mediocre decent</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  love great fantastic excellent good love great...  positive\n",
       "1  love great fantastic excellent good love great...  positive\n",
       "2  bad terrible awful horrible poor bad terrible ...  negative\n",
       "3  bad terrible awful horrible poor bad terrible ...  negative\n",
       "4                  okay fine average mediocre decent   neutral"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'n_neighbors': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifiers\n",
    "# KNN with GridSearchCV\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters for KNN:\", grid.best_params_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=grid.best_params_['n_neighbors'])\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to classify the sentiment\n",
    "def classify_sentiment(text, model):\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    if model == nb:\n",
    "        prediction = model.predict(text_vector.toarray())\n",
    "    else:\n",
    "        prediction = model.predict(text_vector)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the interactive UI\n",
    "def on_button_click(b):\n",
    "    model_name = model_widget.value\n",
    "    text = text_widget.value\n",
    "    if model_name == 'KNN':\n",
    "        model = knn\n",
    "    elif model_name == 'Naive Bayes':\n",
    "        model = nb\n",
    "    elif model_name == 'SVM':\n",
    "        model = svm\n",
    "    sentiment = classify_sentiment(text, model)\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        print(f'Sentiment: {sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309c43503f8a47499816d72a05f5bab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Model:', options=('KNN', 'Naive Bayes', 'SVM'), value='KNNâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the widgets\n",
    "model_widget = widgets.Dropdown(\n",
    "    options=['KNN', 'Naive Bayes', 'SVM'],\n",
    "    value='KNN',\n",
    "    description='Model:'\n",
    ")\n",
    "text_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something...',\n",
    "    description='Text:'\n",
    ")\n",
    "button = widgets.Button(description=\"Classify\")\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create the layout\n",
    "ui = VBox([HBox([model_widget, text_widget, button]), output])\n",
    "\n",
    "# Display the UI\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "1. **Data Setup:** We use a small sample dataset for demonstration purposes. In a real-world scenario, you would have a larger dataset of social media posts.\n",
    "2. **Preprocessing and Vectorization:** We use TfidfVectorizer to convert text data into numerical format, removing English stop words.\n",
    "3. **Model Training:** We train KNN, Naive Bayes, and SVM classifiers on the preprocessed data.\n",
    "4. **Interactive UI:** Using `ipywidgets`, we create an interactive interface where users can select a model and input text to classify its sentiment.\n",
    "\n",
    "### Running the Code:\n",
    "- Copy and paste the code into a Jupyter Notebook or any Python environment that supports IPython widgets.\n",
    "- Run the code cells. The interactive UI will appear, allowing you to input text and select a model to see the sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
